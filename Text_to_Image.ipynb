{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.content\n",
        "image_bytes = query({\n",
        "\t\"inputs\": \"Astronaut riding a horse\",\n",
        "})"
      ],
      "metadata": {
        "id": "ECX0hJEou7oo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import io\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Define the API details\n",
        "API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "# Function to query the API\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    return response.content\n",
        "\n",
        "# Gradio interface function\n",
        "def gr_interface(prompt):\n",
        "    # API request payload\n",
        "    payload = {\"inputs\": prompt}\n",
        "\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Make API request\n",
        "    image_bytes = query(payload)\n",
        "\n",
        "    # Stop timer\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "\n",
        "    try:\n",
        "        # Decode the response content to get the image\n",
        "        pil_image = Image.open(io.BytesIO(image_bytes))\n",
        "    except Exception as e:\n",
        "        # If an error occurs, display an error message\n",
        "        return None, f\"Error: {str(e)}\"\n",
        "\n",
        "    return pil_image, f\"Processing time: {processing_time:.2f} seconds\"\n",
        "\n",
        "# Close any existing Gradio interfaces\n",
        "gr.close_all()\n",
        "\n",
        "# Example prompts\n",
        "example_prompts = [\n",
        "    \"Astronaut riding a horse\",\n",
        "    \"Sunset over the mountains\",\n",
        "    \"Abstract art with vibrant colors\",\n",
        "    \"Cute puppies playing in a garden\",\n",
        "]\n",
        "\n",
        "# Create a Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=gr_interface,\n",
        "    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "    outputs=[gr.Image(label=\"Generated Image\"), gr.Textbox(label=\"Status\")],\n",
        "    title=\"Image Generation with Stable Diffusion\",\n",
        "    description=\"Generate images with Stable Diffusion model\",\n",
        "    allow_flagging=\"never\",\n",
        "    examples=[[prompt] for prompt in example_prompts]\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface and print the link\n",
        "share_link = demo.launch(share=True)\n",
        "print(\"Share this link: \", share_link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "rdkdeqQcvR0B",
        "outputId": "e0601e5e-54c3-4e99-9187-a26ee048b0f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n",
            "Closing server running on port: 7860\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://996f214f3c2fea9ded.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://996f214f3c2fea9ded.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Share this link:  \n"
          ]
        }
      ]
    }
  ]
}